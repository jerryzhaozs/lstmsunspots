{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf #引入TensorFlow框架\n",
    "from tensorflow import keras #引入keras\n",
    "from tensorflow.keras import layers #引入Keras层结构\n",
    "def mode1_alexnet():\n",
    "    model = tf.keras.Sequential(name=\"VGG19Net\")\n",
    "    #第一组第一层卷积使用64个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=64,kernel_size=3,name=\"conv1_1\",input_shape=(224,224,3),activation=\"relu\",padding=\"same\"))\n",
    "    #第一组第二层卷积使用64个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=64,kernel_size=3,name=\"conv1_2\",activation=\"relu\",padding=\"same\"))\n",
    "    #第一组池化层使用的核大小为2、步长为２\n",
    "    model.add(layers.MaxPooling2D ((2, 2),strides=2, name='pool1'))\n",
    "    #第二组第一层卷积使用128个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=128,kernel_size=3,name=\"conv2_1\",activation=\"relu\",padding=\"same\"))\n",
    "    #第二组第二层卷积使用128个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=128,kernel_size=3,name=\"conv2_2\",activation=\"relu\",padding=\"same\"))\n",
    "    #第二组池化层使用的核大小为2、步长为２\n",
    "    model.add(layers.MaxPooling2D ((2, 2),strides=2, name='pool2'))\n",
    "    #第三组第一层卷积使用128个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=128,kernel_size=3,name=\"conv3_1\",activation=\"relu\",padding=\"same\"))\n",
    "    #第三组第二层卷积使用128个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=128,kernel_size=3,name=\"conv3_2\",activation=\"relu\",padding=\"same\"))\n",
    "    #第三组第三层卷积使用128个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=128,kernel_size=3,name=\"conv3_3\",activation=\"relu\",padding=\"same\"))\n",
    "    #第三组第四层卷积使用128个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=128,kernel_size=3,name=\"conv3_4\",activation=\"relu\",padding=\"same\"))\n",
    "    #第三组池化层使用的核大小为2、步长为２\n",
    "    model.add(layers.MaxPooling2D ((2, 2),strides=2, name='pool3'))\n",
    "    #第四组第一层卷积使用256个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=256,kernel_size=3,name=\"conv4_1\",activation=\"relu\",padding=\"same\"))\n",
    "    #第四组第二层卷积使用256个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=256,kernel_size=3,name=\"conv4_2\",activation=\"relu\",padding=\"same\"))\n",
    "    #第四组第三层卷积使用256个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=256,kernel_size=3,name=\"conv4_3\",activation=\"relu\",padding=\"same\"))\n",
    "    #第四组第四层卷积使用256个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=256,kernel_size=3,name=\"conv4_4\",activation=\"relu\",padding=\"same\"))\n",
    "    #第四组池化层使用的核大小为2、步长为２\n",
    "    model.add(layers.MaxPooling2D ((2, 2),strides=2, name='pool4'))\n",
    "    #第五组第一层卷积使用512个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=512,kernel_size=3,name=\"conv5_1\",activation=\"relu\",padding=\"same\"))\n",
    "    #第五组第二层卷积使用512个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=512,kernel_size=3,name=\"conv5_2\",activation=\"relu\",padding=\"same\"))\n",
    "    #第五组第三层卷积使用512个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=512,kernel_size=3,name=\"conv5_3\",activation=\"relu\",padding=\"same\"))\n",
    "    #第五组第四层卷积使用512个核函数，卷积核大小为 3，步长为1，使用ReLU激活函数\n",
    "    model.add(layers.Conv2D(filters=512,kernel_size=3,name=\"conv5_4\",activation=\"relu\",padding=\"same\"))\n",
    "    #第五组池化层使用的核大小为2、步长为２\n",
    "    model.add(layers.MaxPooling2D ((2, 2),strides=2, name='pool5'))\n",
    "    #对前面提取的特征图操作进行展平操作\n",
    "    model.add(layers.Flatten (name=\"flatten\"))\n",
    "    #输出节点为4096的全连接层操作\n",
    "    model.add(layers.Dense (units=4096,activation=\"relu\",name=\"fc1\"))\n",
    "    #为了防止过拟合，引入dropout操作，丢失概率为0.5\n",
    "    model.add(layers.Dropout(rate=0.5))\n",
    "    #输出节点为4096的全连接层操作\n",
    "    model.add(layers.Dense (units=4096,activation=tf.nn.relu,name=\"fc2\"))\n",
    "    #为了防止过拟合，引入dropout操作，丢失概率为0.5\n",
    "    model.add(layers.Dropout (rate=0.5))\n",
    "    #最后进行类别数目的全连接\n",
    "    model.add(layers.Dense(units=1000,name='fc3'))\n",
    "    return model\n",
    "if __name__==\"__main__\":\n",
    "    y = mode1_alexnet()\n",
    "    print(y.summary())\n",
    "    keras.utils.plot_model(y,\"./image/vgg19net.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
